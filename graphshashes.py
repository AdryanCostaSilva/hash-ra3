# -*- coding: utf-8 -*-
"""GraphsHashes.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lxbCQ1-IIYzPo6k9UnsfUFl1NKi0Maru
"""

# Install libraries (Seaborn is optional but nice for plots)
!pip install matplotlib seaborn --quiet

# Imports
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import pandas as pd

# Set seaborn style
sns.set(style="whitegrid")

# Define the data as dictionaries
data = {
    "Double Hash": {
        "1000": {"insert_ms": 1192.772, "collisions": 9005669, "search_ms": 0.396, "min_gap":0, "max_gap":0, "avg_gap":0},
        "10000": {"insert_ms": 13313.828, "collisions": 900072088, "search_ms": 1.013, "min_gap":0, "max_gap":0, "avg_gap":0},
        "100000": {"insert_ms": 387264.526, "collisions": 90000812990, "search_ms": 9.176, "min_gap":0, "max_gap":0, "avg_gap":0},
        "10000_9000": {"insert_ms": 1600.170, "collisions": 23655, "search_ms": 2.486, "min_gap":1, "max_gap":6, "avg_gap":1.12}
    },
    "Multiplication Hash": {
        "1000": {"insert_ms": 1350.495, "collisions": 49648, "search_ms": 2.644, "min_gap":0, "max_gap":0, "avg_gap":0, "top1":23, "top2":20, "top3":20},
        "10000": {"insert_ms": 12081.619, "collisions": 499418, "search_ms": 8.668, "min_gap":0, "max_gap":0, "avg_gap":0, "top1":25, "top2":23, "top3":23},
        "100000": {"insert_ms": 126444.102, "collisions": 5002137, "search_ms": 39.181, "min_gap":1, "max_gap":1, "avg_gap":1, "top1":26, "top2":26, "top3":26},
        "10000_9000": {"insert_ms": 1179.875, "collisions": 4030, "search_ms": 2.138, "min_gap":1, "max_gap":9, "avg_gap":1.68, "top1":7, "top2":6, "top3":6}
    },
    "Quadratic Hash": {
        "1000": {"insert_ms": 1025.130, "collisions": 9004646, "search_ms": 0.496, "min_gap":0, "max_gap":0, "avg_gap":0},
        "10000": {"insert_ms": 11303.311, "collisions": 900066576, "search_ms": 1.699, "min_gap":0, "max_gap":0, "avg_gap":0},
        "100000": {"insert_ms": 342569.568, "collisions": 9000012804, "search_ms": 12.619, "min_gap":0, "max_gap":0, "avg_gap":0},
        "10000_9000": {"insert_ms": 1463.219, "collisions": 15679, "search_ms": 0.962, "min_gap":1, "max_gap":4, "avg_gap":1.18}
    }
}

"""# Cell 1: Double Hash"""

import matplotlib.pyplot as plt
import seaborn as sns

# Dados do Double Hash
double_data = data["Double Hash"]

tabelas = ["1000","10000","100000","10000_9000"]
tempos_insercao = [double_data[t]["insert_ms"] for t in tabelas]
tempos_busca = [double_data[t]["search_ms"] for t in tabelas]
colisoes = [double_data[t]["collisions"] for t in tabelas]

# Gráfico tempo de inserção
plt.figure(figsize=(10,5))
sns.barplot(x=tabelas, y=tempos_insercao, palette="Blues_d")
plt.title("Double Hash - Tempo de Inserção por Tamanho da Tabela (ms)")
plt.ylabel("Tempo de Inserção (ms)")
plt.xlabel("Tamanho da Tabela / Conjunto de Dados")
plt.show()

# Gráfico de colisões
plt.figure(figsize=(10,5))
sns.barplot(x=tabelas, y=colisoes, palette="Reds_d")
plt.title("Double Hash - Colisões por Tamanho da Tabela")
plt.ylabel("Número de Colisões")
plt.xlabel("Tamanho da Tabela / Conjunto de Dados")
plt.show()

# Gráfico tempo de busca
plt.figure(figsize=(10,5))
sns.barplot(x=tabelas, y=tempos_busca, palette="Greens_d")
plt.title("Double Hash - Tempo de Busca por Tamanho da Tabela (ms)")
plt.ylabel("Tempo de Busca (ms)")
plt.xlabel("Tamanho da Tabela / Conjunto de Dados")
plt.show()

"""# Cell 2: Multiplication Hash"""

# Dados do Multiplication Hash
mul_data = data["Multiplication Hash"]

tabelas = ["1000","10000","100000","10000_9000"]
tempos_insercao = [mul_data[t]["insert_ms"] for t in tabelas]
tempos_busca = [mul_data[t]["search_ms"] for t in tabelas]
colisoes = [mul_data[t]["collisions"] for t in tabelas]
top1 = [mul_data[t]["top1"] for t in tabelas]

# Gráfico tempo de inserção
plt.figure(figsize=(10,5))
sns.barplot(x=tabelas, y=tempos_insercao, palette="Blues_d")
plt.title("Multiplication Hash - Tempo de Inserção por Tamanho da Tabela (ms)")
plt.ylabel("Tempo de Inserção (ms)")
plt.xlabel("Tamanho da Tabela / Conjunto de Dados")
plt.show()

# Gráfico de colisões
plt.figure(figsize=(10,5))
sns.barplot(x=tabelas, y=colisoes, palette="Reds_d")
plt.title("Multiplication Hash - Colisões por Tamanho da Tabela")
plt.ylabel("Número de Colisões")
plt.xlabel("Tamanho da Tabela / Conjunto de Dados")
plt.show()

# Gráfico top lista
plt.figure(figsize=(10,5))
sns.barplot(x=tabelas, y=top1, palette="Purples_d")
plt.title("Multiplication Hash - Maior tamanho das listas encadeadas")
plt.ylabel("Nós na maior lista")
plt.xlabel("Tamanho da Tabela / Conjunto de Dados")
plt.show()

# Gráfico tempo de busca
plt.figure(figsize=(10,5))
sns.barplot(x=tabelas, y=tempos_busca, palette="Greens_d")
plt.title("Multiplication Hash - Tempo de Busca por Tamanho da Tabela (ms)")
plt.ylabel("Tempo de Busca (ms)")
plt.xlabel("Tamanho da Tabela / Conjunto de Dados")
plt.show()

"""# Cell 3: Quadratic Hash"""

# Dados do Quadratic Hash
quad_data = data["Quadratic Hash"]

tabelas = ["1000","10000","100000","10000_9000"]
tempos_insercao = [quad_data[t]["insert_ms"] for t in tabelas]
tempos_busca = [quad_data[t]["search_ms"] for t in tabelas]
colisoes = [quad_data[t]["collisions"] for t in tabelas]

# Gráfico tempo de inserção
plt.figure(figsize=(10,5))
sns.barplot(x=tabelas, y=tempos_insercao, palette="Blues_d")
plt.title("Quadratic Hash - Tempo de Inserção por Tamanho da Tabela (ms)")
plt.ylabel("Tempo de Inserção (ms)")
plt.xlabel("Tamanho da Tabela / Conjunto de Dados")
plt.show()

# Gráfico de colisões
plt.figure(figsize=(10,5))
sns.barplot(x=tabelas, y=colisoes, palette="Reds_d")
plt.title("Quadratic Hash - Colisões por Tamanho da Tabela")
plt.ylabel("Número de Colisões")
plt.xlabel("Tamanho da Tabela / Conjunto de Dados")
plt.show()

# Gráfico tempo de busca
plt.figure(figsize=(10,5))
sns.barplot(x=tabelas, y=tempos_busca, palette="Greens_d")
plt.title("Quadratic Hash - Tempo de Busca por Tamanho da Tabela (ms)")
plt.ylabel("Tempo de Busca (ms)")
plt.xlabel("Tamanho da Tabela / Conjunto de Dados")
plt.show()

"""# Cell 4: Comparando todos os hashes – Tempo de Inserção"""

tamanhos = ["1000","10000","100000","10000_9000"]
hashes = ["Double Hash", "Multiplication Hash", "Quadratic Hash"]

plt.figure(figsize=(12,6))
for h in hashes:
    tempos = [data[h][t]["insert_ms"] for t in tamanhos]
    plt.plot(tamanhos, tempos, marker='o', label=h)

plt.title("Comparação de Tempo de Inserção - Todos os Hashes")
plt.ylabel("Tempo de Inserção (ms)")
plt.xlabel("Tamanho da Tabela / Conjunto de Dados")
plt.legend()
plt.show()

"""# Cell 5: Comparando todos os hashes – Tempo de Busca"""

plt.figure(figsize=(12,6))
for h in hashes:
    tempos = [data[h][t]["search_ms"] for t in tamanhos]
    plt.plot(tamanhos, tempos, marker='o', label=h)

plt.title("Comparação de Tempo de Busca - Todos os Hashes")
plt.ylabel("Tempo de Busca (ms)")
plt.xlabel("Tamanho da Tabela / Conjunto de Dados")
plt.legend()
plt.show()

"""# Cell 6: Ilustração de complexidade (O(n), O(1))"""

tabelas = ["1000","10000","100000","10000_9000"]

plt.figure(figsize=(12,6))

# Inserção
for hash_name in data:
    tempos_insercao = [data[hash_name][t]["insert_ms"] for t in tabelas]
    plt.plot(tabelas, tempos_insercao, marker='o', label=f"{hash_name} (inserção)")

# Busca
for hash_name in data:
    tempos_busca = [data[hash_name][t]["search_ms"] for t in tabelas]
    plt.plot(tabelas, tempos_busca, marker='x', linestyle='--', label=f"{hash_name} (busca)")

plt.title("Comparação de Performance dos Hashes (Tempo de Inserção e Busca)")
plt.xlabel("Tamanho da Tabela / Dados")
plt.ylabel("Tempo (ms)")
plt.yscale('log')  # log para melhor visualização das diferenças grandes
plt.grid(True, linestyle='--', alpha=0.5)
plt.legend()
plt.show()

# Análise de Desempenho dos Algoritmos de Hash

# Preparar dados para visualização
methods = []
sizes = []
insert_times = []
search_times = []
collisions = []
performance_scores = []

for method, datasets in data.items():
    for size, metrics in datasets.items():
        methods.append(method)
        sizes.append(size)
        insert_times.append(metrics['insert_ms'])
        search_times.append(metrics['search_ms'])
        collisions.append(metrics['collisions'])

        # Calcular score de performance (menor é melhor)
        # Normalizar por tamanho para comparação justa
        if size == "10000_9000":
            norm_factor = 10000
        else:
            norm_factor = int(size)

        score = (metrics['insert_ms'] + metrics['search_ms'] * 100) / norm_factor
        performance_scores.append(score)

# Criar DataFrame
df = pd.DataFrame({
    'Método': methods,
    'Tamanho': sizes,
    'Tempo Inserção (ms)': insert_times,
    'Tempo Busca (ms)': search_times,
    'Colisões': collisions,
    'Score Performance': performance_scores
})

# Configurar cores baseadas na performance
def get_performance_color(score):
    if score < 0.5:
        return '#2E8B57'  # Verde escuro (Excelente)
    elif score < 1.0:
        return '#32CD32'  # Verde claro (Bom)
    elif score < 2.0:
        return '#FFD700'  # Amarelo (Regular)
    elif score < 5.0:
        return '#FF8C00'  # Laranja (Ruim)
    else:
        return '#DC143C'  # Vermelho (Péssimo)

def get_performance_label(score):
    if score < 0.5:
        return 'Excelente'
    elif score < 1.0:
        return 'Bom'
    elif score < 2.0:
        return 'Regular'
    elif score < 5.0:
        return 'Ruim'
    else:
        return 'Péssimo'

# Visualização principal
fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(18, 14))
fig.suptitle('Análise de Performance dos Algoritmos de Hash', fontsize=18, fontweight='bold')

# 1. Tempo de Inserção por Tamanho
colors1 = [get_performance_color(score) for score in performance_scores]
scatter1 = ax1.scatter(df['Tamanho'], df['Tempo Inserção (ms)'],
                      c=colors1, s=120, alpha=0.8, edgecolors='black', linewidth=1.5)
ax1.set_xlabel('Tamanho do Dataset', fontsize=12)
ax1.set_ylabel('Tempo de Inserção (ms)', fontsize=12)
ax1.set_title('Tempo de Inserção vs Tamanho', fontsize=14, fontweight='bold')
ax1.set_yscale('log')

# Adicionar labels dos métodos
for i, method in enumerate(df['Método']):
    ax1.annotate(method.split()[0], (df['Tamanho'].iloc[i], df['Tempo Inserção (ms)'].iloc[i]),
                xytext=(5, 5), textcoords='offset points', fontsize=9, fontweight='bold')

# 2. Colisões por Método
pivot_collisions = df.pivot(index='Tamanho', columns='Método', values='Colisões')
pivot_collisions.plot(kind='bar', ax=ax2, color=['#FF6B6B', '#4ECDC4', '#45B7D1'], width=0.8)
ax2.set_ylabel('Número de Colisões', fontsize=12)
ax2.set_title('Colisões por Método e Tamanho', fontsize=14, fontweight='bold')
ax2.set_yscale('log')
ax2.tick_params(axis='x', rotation=45)
ax2.legend(fontsize=10)

# 3. Tempo de Busca
pivot_search = df.pivot(index='Tamanho', columns='Método', values='Tempo Busca (ms)')
pivot_search.plot(kind='bar', ax=ax3, color=['#FF9999', '#66B2FF', '#99FF99'], width=0.8)
ax3.set_ylabel('Tempo de Busca (ms)', fontsize=12)
ax3.set_title('Tempo de Busca por Método', fontsize=14, fontweight='bold')
ax3.tick_params(axis='x', rotation=45)
ax3.legend(fontsize=10)

# 4. Gráfico de Performance mais bonito (substituindo o heatmap)
pivot_score = df.pivot(index='Método', columns='Tamanho', values='Score Performance')

# Criar gráfico de barras agrupadas para performance
x = np.arange(len(pivot_score.index))
width = 0.2
sizes_list = list(pivot_score.columns)

colors_performance = ['#2E8B57', '#FFD700', '#FF8C00', '#DC143C']

for i, size in enumerate(sizes_list):
    scores = pivot_score[size].values
    colors = [get_performance_color(score) for score in scores]
    bars = ax4.bar(x + i*width, scores, width, label=f'{size} elementos',
                   color=colors, alpha=0.8, edgecolor='black', linewidth=1)

    # Adicionar valores nas barras
    for j, (bar, score) in enumerate(zip(bars, scores)):
        height = bar.get_height()
        ax4.text(bar.get_x() + bar.get_width()/2., height + height*0.01,
                f'{score:.2f}', ha='center', va='bottom', fontsize=9, fontweight='bold')

ax4.set_xlabel('Métodos de Hash', fontsize=12)
ax4.set_ylabel('Score de Performance (menor = melhor)', fontsize=12)
ax4.set_title('Comparação de Performance por Método e Tamanho', fontsize=14, fontweight='bold')
ax4.set_xticks(x + width * 1.5)
ax4.set_xticklabels([method.replace(' Hash', '') for method in pivot_score.index])
ax4.legend(fontsize=10)
ax4.set_yscale('log')

plt.tight_layout()
plt.show()

# Adicionar labels de performance
for i, (bar, score, label) in enumerate(zip(bars, method_avg_scores.values, labels_ranking)):
    width = bar.get_width()
    ax5.text(width + width*0.02, bar.get_y() + bar.get_height()/2,
             f'{score:.3f} - {label}', ha='left', va='center', fontsize=12, fontweight='bold')

ax5.set_xlabel('Score Médio de Performance (menor = melhor)', fontsize=14)
ax5.set_title('Ranking Geral de Performance dos Algoritmos', fontsize=16, fontweight='bold')
ax5.set_xlim(0, max(method_avg_scores.values) * 1.3)

# Adicionar legenda de cores
legend_elements = [
    plt.Rectangle((0,0),1,1, facecolor='#2E8B57', label='Excelente (< 0.5)'),
    plt.Rectangle((0,0),1,1, facecolor='#32CD32', label='Bom (0.5-1.0)'),
    plt.Rectangle((0,0),1,1, facecolor='#FFD700', label='Regular (1.0-2.0)'),
    plt.Rectangle((0,0),1,1, facecolor='#FF8C00', label='Ruim (2.0-5.0)'),
    plt.Rectangle((0,0),1,1, facecolor='#DC143C', label='Péssimo (> 5.0)')
]
ax5.legend(handles=legend_elements, loc='lower right', fontsize=11)

plt.tight_layout()
plt.show()